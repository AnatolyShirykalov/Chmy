\section{Как решать задачу МНК}
Сегодня закончим вопросы переопределённых систем. Будем считать, что у нас имеется матрица $A$ размера $m\times n$, причём чётко $m>n$. При этом пусть $\rang(A)\le n$. Писать $Ax=b$ мы не можем. Ставим задачу наименьших квадратов
\[
  \min\limits_x\|b - Ax\|^2_2.
\]
Если $\rang(A)=n$, то можно написать нормальную систему, получить её решение $\hat x$. Подход, мы обсудили, плохой, он обусловленность матрицы возмодит в квадрат. Но хоть как-то.

Пусть теперь $\rang(A)<n$. Что тогда делать. Есть разные подходы. Мы рассмотрим один.

Итак работаем с системами, в которых либо $\rang(A)<n$, либо $\rang(A)=n$, то матрица плохо обусловлена.

Я не помню, давал ли такое свойство. Если нет, то в качестве упражнения.
\begin{Ut}
  Пусть $Q$ ортогональная, тогда $\forall\ x\pau \|Qx\| = \|x\|$.
\end{Ut}

Возьмём норму невязки $\|Ax-b\|_2$. Нам её надо минимизировать. Пусть $A$ размера $m\times n$. У нас есть сингулярное разложение
\[
  A = U\Sigma V^T,
\]
где $U(m\times m)$, $V(n\times n)$ ортогональные, $\rang(A)=k$, $\Sigma$ имеет диагональный блок слева сверху $k\times k$ и остальные нули.
\[
  \|Ax-b\|_2=\|A V V^T x - b\| = \big\|U^T(AVV^T - b)\big\|_2 = \|\Sigma \underbrace{V^T x}_z - \underbrace{U^Tb}_b\|_2 = \|\Sigma z - d\|.
\]
Матрица $\Sigma$, слава богу, у нас диагональная, хоть и не квадратная, какая смогла быть.

Положим $z_j = \frac{d_j}{\sigma_j}$, где $\sigma_j$ "--- сингулярное значение, $j=1,\dots,k$. В этих обозначениях
\[
  \|Ax-b\|^2 = \RY j1k(\sigma_j z_j - d_j)^2 +\RY j{k+1}n(0\cdot z_j - d_j) + \RY j{n+1}md_j^2.
\]
Таким образом $z_j$ при $j=n+1,\dots,n$ можно брать любые. Мы уже можем ещё сказать, что при $k=n$
\[
  \min\|Ax-b\| = \sqrt{\RY{j}{n+1}m d_j^2}.
\]
То есть если сингулярное разложение выполнено, то дальше всё достаточно легко. Но само разложение довольно нетривиально. Есть пакеты, вопрос только, сколько они будут работать.
\subsection{Выравнивание данных методом МНК}
Это пример обработки модели, основанной на МНК.

Предположим заказчик исследует физический или биологический закон. Причём формально $y=y(t)$. Всё, что заказчик может, поставить эксперимент. Получаем $(t_i,y_i)$. Таких пар можно получить от заказчика сколько угодно.

Мы такие подумали и взяли систему линейно независимых функций $\big\{\phi_i(t)\big\}$, $i=1,\dots,n$. Модель будем строить такой
\[
  y(t)\approx \RY j1n c_j \phi_j(t).
\]
Всё вроде хорошо. А дальше оказывается, что точек измерений на нас вывалили больше, чем $n$, чем то число, которое мы можем по каким-то причинам можно себе позволить в качестве количества линейно независимых функций. А эксперимент настолько дорогой, что заказчик непременно хочет использовать все его данные.

Попытаемся составить вектор невязок.
\[
  r_i = \RY j1n c_j \phi_i(t_i) - y_i.
\]
Ну и попытаемся минимизировать его норму. То есть задачу поставим такую
\[
  \|\ol r\|_2^2 \to \min.
\]

Я ничего нового не рассказываю. Но на всякий случай формально напишем постановку задачи.
\[
  \|\ol r\|^2_2 = \RY i1m\bigg(\RY j1n c_j\phi_j(t_i) - y_i\bigg)^2
\]
Переменными являются $c_j$. Нам надо считать
\[
  \CP{\|\ol r\|^2_2}{c_k} = 0,\quad k=1,\dots,n.
\] 
Получается
\[
 \RY j1n\bigg(\RY i1m\phi_j(t_i)\phi_k(t_i)\bigg)c_j = \RY i1m y_i\phi_k(t_i). 
\]
Здесь $k=1,\dots,n$. Явно это система алгебраических уравнений. Надо её записать в более человеческом виде, чтобы можно было наши знания применять.
\[
 P\ol C = \ol f,
\]
где $P_{kj} = \RY i1m\phi_k(t_i) \phi_j(t_i)$, $f_k = \RY i1m y_i\phi_k(t_i)$. Можно представить матрицу $P$  в виде
\[
  P = \Phi^T\Phi,\qquad
  \Phi = \begin{pmatrix}
\phi_1(t) & \dots & \phi_n(t) \\
\vdots & \ddots & \vdots \\
\phi_1(t_{n)} & \dots \phi_m(t_n)
\end{pmatrix}
\]
При этом $\ol f = \Phi^T\ol y$. Можем решать задачу в такой постановке
\[
  \min\limits_{\ol C} \|\Phi \ol C - \ol y\|.
\]

Пусть теперь простейшая линейная задача метода наименьшах квадратов. Есть $(t_i,y_i)$, $t=1,\dots,m$. Пусть $n=2$, $\phi_1(t) = 1$, $\phi_2(t) = t$. Таким образом
\[
  y(t) =c_1 + c_2 t.
\]
Фактически мы строим прямую, до которой точки находятся максимально близко. Система имеет вид
\[
  P\ol C = \ol f,\quad
  P = \begin{pmatrix}
  m & \RY i1m t_i\\
\RY i1m t_i & \RY i1m t_i^2
\end{pmatrix},\quad
\ol f = \begin{pmatrix}
\RY i1m y_i\\
\RY i1m t_iy_i
\end{pmatrix}.
\]

\section{Итерационные методы}
Решается система $Ax = b$, матрица невырожденная и $N\times N$. Проблема у нас здесь будет с памятью. Массив $N^2$ матрицы помещаться не будет. Либо можно хранить формулы, по которым коэффициенты матрицы считаются, либо матрица у нас будет разреженная: количество ненулевых элементов конечно и не зависит от $N$. Типичный представитель тридиагональная матрица, которую обрабатывали методом прогонки. 

Если здесь затеять прямой метод, как метод Гаусса и вообще всё, что мы изучали, элементы матрицы начнут куда-то перемещаться, например, строку будем к строке прибавлять. А нам желательно проделывать процедуры, которые ничего не делают с самой матрицу $A$. Обращаться матрицу мы не будем, всё это под запретом. Матрица может только дёшево умножаться на вектор. Эта операция имеет порядок сложности $N$.

Заменим нашу систему на эквивалентную. Как правило вот такую используют
\[
  x = Bx + c.
\]
Как это сделать, способов на самом деле вагон. $x = x - D(Ax - b)$. Вся экзотика заключается в матрице $D$, выбираем любую.

Если всё получилось, то берём $x^0$. А далее
\[
  x^{n+1} = B x^n + C.
\]
Ну и как выбрать матрицы, чтобы метод сходился, мы и будем обсуждать.

Начнём немножко не с начала. Рассмотрим систему $x = Bx + c$. Пусть $\ol x$ "--- решение. Возьмём какой-то $x^0$. И далее будем шагать $x^{n+1} = Bx^n + c$.

Пусть $\|B\|<1$. Тогда мы знаем, что $\exists\ (E-B)^{-1}$. Тогда система $(E-B)x = c$ разрешима. Ну хорошо, а итерационный метод при этому сходится? Имеем
\[
  \ol x = B\ol x + c;\quad x^{n+1} = B x^n + c,\quad x^0.
\]
Спрашивается, верно ли, что $\|x^n - \ol x\|\to 0$.

Рассмотрим $z^n = x^n - \ol x$, $z^{n+1} = Bz^n$. Понятно, что
\[
  \|z^{n+1}\| \le \|B\| \|z^n\|\imp \|z^n\| \le \|B\|^n \|z^0\|\to 0.
\]
Это всё хорошо, но норма это не матричный инвариант. Вдруг от выбора нормы от чего-то зависит. Вдруг мы получим в одной норме, что не сходится. Но может и в другой сходится.

\begin{The}
 Пусть $\exists!\ x\colon x = Bx + c$ (здесь $\|B\|$ может быть не обязательно меньше единицы). Тогда следующие утверждения эквивалентны
\begin{enumerate}
 \item $x^{n+1} = Bx^n + \ol c$ сходится для всякого $x^0$;
\item Все собственные значения $B$ по модулю меньше единички.
\end{enumerate}
\end{The}
\begin{Proof}
 Утверждение на самом деле сильное. Нам потребуется дополнительная конструкция.
\begin{Lem}
 Пусть $\exists\ q>0\colon \big|\lambda(\beta)\big|<q$ (тут написано, что все собственные значения матрицы $B$ по модулю меньше $q$). Тогда существует $\Lambda = D^{-1}BD$, где $\|\Lambda\|_\infty<q$, $D$ "--- некоторая невырожденная матрица.
\end{Lem}
\begin{proof}
  Обозначим $\theta = q - \max\limits_i|\lambda_i|$, $\lambda(B) = \lambda_1,\lambda_2,\dots$

Рассмотрим матрицу $\theta^{-1}B$. Какие у неё собственные числа
\[
  \lambda(\theta^{-1}B)\sim \theta^{-1}\lambda_i.
\]
Приведём $\theta^{-1}B$ к жордановой нормальной форме. Что это такое. Есть некоторая невырожденная матрица $D\colon D^{-1}(\theta^{-1}B)D$ имеет вид
\[
\begin{pmatrix}
 \theta^{-1} \lambda_1 & \alpha_{12} &  & & \\
  & \theta^{-1} \lambda_2 & \alpha_{23} & & \\
  & & \ddots & \alpha_{34} & \\
 & 0 & & \ddots & \ddots
\end{pmatrix}
\]
Здесь $\alpha_{ij} = 0,1$. При этом $D^{-1}BD$ имеет вид
\[
\begin{pmatrix}
 \lambda_1 & \alpha_{12} &  & & \\
  & \lambda_2 & \alpha_{23} & & \\
  & & \ddots & \alpha_{34} & \\
 & 0 & & \ddots & \ddots
\end{pmatrix} = \Lambda.
\]
Отсюда $|\lambda_j| + |\theta \alpha_{j,j+1}\le |\lambda_j| + \theta < q$.
\end{proof}

Сначала достаточность. Пусть $\big|\lambda(B)\big| <1$. Тогда найдётся $q\colon 0<q<1\colon \big|\lambda(B)\big|<q$. При этом $z^n = B^nz^0$. По лемме $B = D\Lambda D^{-1}$. При этом
\[
  B^n = D \Lambda^n D^{-1}.
\]
Тогда $\|B^n\|_\infty \le \|D\| \|\Lambda\|^n_\infty \|D^{-1}\|_\infty \le \|D\| \|D^{-1}\| q^n\to 0$.
Отсюда получаем что $\|z^n\|_\infty\le \|B^n\|\|z^0\|\to 0$.

Теперь необходимость. Пусть у нас существует $\lambda_i\colon |\lambda_i|\ge 1$. Предъявим начальное приближение, при котором сходимость не получится. Обозначим решение $\ol x = B\ol x + c$, пусть $|\lambda_k|\ge 1$, Рассмотрим соответствующий собственный вектор $B\ol e^k = \lambda_k \ol e^k$. Пусть $x^0 = \ol x + \ol e^k$. Тогда $z^0 = x^0 - \ol x = \ol e^k$. Соответственно
\[
  z^1 = Bz^0 = \lambda_k \ol e^k,\quad z^n (\lambda_k)^n \ol e_k.
\]
И у нулю эта норма стремиться совершенно не собирается.

\end{Proof}
Если стартовать с другого начального $x^0$, то ошибки при вычислениях, машинные, будут накапливаться и постепенно $\ol e^k$ появится. Однако можно каждый раз проецировать $x^n$ на ортогональное дополнение $\ol e^k$.

Метод $x^{n+1} = Bx^n + c$ называется методом простой итерации.

Пусть есть $A = A^T>0$ и мы собрались решать систему вида $Ax = b$. Хотим решать итерациями. Тогда простейший способ
\[
  x = x - \alpha (Ax -b).
\]
Тогда итерационный процесс имеет вид
\[
  x^{n+1} = x^n - \lambda(Ax - b).
\]
Вычитаем одно из другого и получаем формулу на погрешность
\[
  z^{n+1} = (E- \alpha A)z^n.
\]
Так как $B = E-\alpha A$, то $B^T=B$ имеет место симметричность матрицы $B$. Мы хотим, чтобы
\[
  \big|\lambda(E-\alpha A)\big|<1.
\]
С другой стороны, а что такое вторая норма матрицы $B$
\[
  \|B\|_2 = \sqrt{\max\lambda(B^TB)}.
\]
Так как матрица симметрична
\[
  \|B\|_2 = \sqrt{\max\lambda(B^2)} = \max\big|\lambda(B)\big|.
\]
Очень удобно. А что такое собственные значения матрицы $B$. Имеем
\[
 \|B\|_2 = \max\limits_{\lambda(A)} |1-\alpha \lambda|.
\]
Если мы сможем получить, что $\max\limits_{\lambda(A)}|1-\alpha\lambda|\le q$, то будет сходимость итерационного метода.

\noindentВозникает следующая минимаксная задача.
\[
  q = \min\limits_\alpha\bigg(\max\big|1-\alpha\lambda(A)\big|\bigg).
\]
В таком виде эта задача нерешаема. Эта задача сложнее, чем решить систему. Огрубим задачу. У нас ведь $A= A^T>0$. Тогда вдруг у нас получится найти оценку $0<m\le \lambda(A)\le M<\infty$. Тогда
\[
  q\le \min\limits_\alpha\bigg(\max\limits_{m\le \lambda \le M}\big|1-\alpha \lambda\big|\bigg).
\]
Ну давайте эту задачу решим как она есть. Рисуем графики нашего модуля с горязонтальной осью $\lambda$ при разных $\alpha$. Ответ такой: $\alpha_0 = \frac2{m+M}$. Тогда $q_0 = \frac{M-m}{m+M}$. И у нас получается оценка сходимости
\[
  \|z^n\|_2\le \left( \frac{M-m}{M+m} \right)^n\|z^0\|_2.
\]
В практической ситуации такая оценка сходимости не работает. Она как правило получается $q$ близко к единице.
