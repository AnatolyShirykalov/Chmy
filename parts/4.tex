\section{Лекция 4}
В прошлый раз мы с вами остановились на чём. Имеется гильбертоо пространство $R$ со скалярным произведением $(f,g)$ и, соответственно, норма $\|f\| = \sqrt{(f,f)}$. Имеелась линейно независимая система $g_1,\dots,g_n$, какая-то функция $f$. Нужно было построить элемент наилучшего приближения.
\[
  f\sim \RY j1n c_j g_j.
\]
\begin{Def}
  Элементом наилучшего приближения называется кобминация $\RY j1n c_j^0 g_j$, для которой
  \[
    \bigg\|f - \RY j1n c_j^0 g_j\bigg\| = \min_{c_1,\dots,c_n} \bigg\|f - \RY j1n c_j g_j\bigg\|.
  \]
\end{Def}
Находится из системы $G \ol c = \ol F$, где $G_{ij} = (g_i,g_j)$, $F_i = (f,g_i)$.

Вернёмся с высоких материй. Пусть работаем в $\L_2[-1,1]$. Здесь $(f,g) = \int\limits_{-1}^1 fg\,dx$.

Вводили определение числа обусловленности матрицы $\cond(A) = \|A\|\cdot \|A^{-1}\|$. Если выполняется положительная определённость и симметричность $A = A^T>0$, то есть второе определение
\[
  \cond_2(A) = \frac{\lambda_{\max}(A)}{\lambda_{min}(A)}.
\]

При этом $\|A\|_2 = \sup\limits_{x\ne 0} \frac{\|Ax\|_2}{\|x\|_2}$.

Если за базис брать многочлены, число обусловленности будет неограниченно очень быстро расти. С вычислительной точки зрения это не годится.

Будем использовать функции с конечным носителем. Начало будет не очень жизнерадостным. Мы разобьём наш отрезок на $n$ точек $x_1,x_2,\dots,x_n$. Будем считать, что сеточка равномерная $x_{i+1}-x_i = h$. В качестве $i$-й функции $g_i(x)$ возьмём такую, что $g_i(x_i) = 1$, $g_i$ линейная на $[x_{i-1},x_i]$ и линейная на $[x_{i}, x_{i+1}]$. Вне отрезка $[x_{i-1},x_{i+1}]$ $g_i\equiv 0$ и $g_i$ непрерывна.

Матрица $G_{ij} = (g_i,g_j)$ будет три-диагональна, то есть считать надо только $G_{i,i\pm1}$, $G_{ii}$, остальные нули.

Считаем для \[g_i = \begin{cases}
  1 \frac{-x}h,&x\in[0,h];\\
  1+\frac xh,&x\in[-h,0].
\end{cases}\]
скалярное произведением
\[
  (g_i,g_i) = 2\int\limits_0^h(1-\frac xh)^2\,dx = \frac2h3.
\]
Ну и по краям отрезок интегрирования напополам обрезан. Значит, $(g_1,g_1) = (g_n,g_n)=\frac h3$.

Теперь считаем
\[
  (g_i,g_{i+1}) = \int\limits_0^h\left(1-\frac xh\right)\frac xh\,dx = \frac h6 = (g_i,g_{i-1}).
\]
Таким образом, получается матрица $G$
\[
  \begin{pmatrix}
    h/3 & h/h & 0 &\dots\\
    h/6 & 2h/3 & 0 & \dots\\
    0 & \ddots & \ddots & \ddots &\dots
  \end{pmatrix}
\]

Правая часть $F_i = \int\limits_{-1}^1 fg_i\,dx = \int\limits_{x_i-h}^{x_i+h} f(x) g_i(x)\,dx$. Мы может и не сможем интеграл взять. Давайте приблизим
\[
  F_i \approx  f(x_i) \int\limits_{x_i-h}^{x_i+h} g_i(x)\,dx.
\]

Насколько это будет хорошее приближение "--- упражнение.

Можно искать второе число обусловленности. Искать собственные значения. Нам нужны оценка сверху и оценка снизу. Обычно теорема, которую сейчас назову, почему-то перестала входить в число обязательных на мехмате.
\subsection{Круги Гершгорина}
Я её в упрощённой постановке сформулирую. Пусть есть Матрица $A$ вещественная и $n\times n$. Так вот все её собственные значения $\lambda_i(A)\in \UN i1n K_i(R_i)$, где круг $K_i(R_i) = \big\{z\colon |z - a_{ii}|\le\sum\limits_{i\ne j}|a_{ij}|\big\}$. Центр в $a_ii$, радиус есть сумма модулей всех недиагональных элементов.

В нашем случае все собственные значения вещественные, так как матрица симметричная. Первой и последней строке соответствует круг $[h/6,h/3]$, остальным точкам соответствует круг $[h/3,h]$. То есть фактически мы можем сказать, что собственные значения нашей матрицы не такие уж ужасные.
\[
  h/6\le \lambda(G)\le h.
\]
Стало быть её число обусловленности
\[
  \cond_2(G) = \frac{\lambda_{\max}}{\lambda_{\min}}\le 6.
\]
Это число, оно не зависит от количества элементов в базисе. Это ситуация почти идеальная. При современном подходе к задачам это идеал, к которому нужно стремиться. Ошибка максимум в 6 раз увеличится.

Теперь такой вопрос. Как эту систему решать.
\subsection{Решение систем линейных уравнений с три-диагональной матрицей}
Решаем систему $Ax = b$. Будем считать, что матрица $A$ у нас вот такая
\[
 A = \begin{pmatrix}
   \alpha_1 & \beta_1   & 0         & 0     & \dots\\
   \gamma_2 & \alpha_2  & \beta 2   & 0     & \dots\\
   0        & \gamma_3  & \alpha_3  & \beta_3 &\dots\\
   0        & \ddots    & \ddots    & \ddots & \ddots\\
 \end{pmatrix}.
\]
Давайте наложим дополнительные требования, которые могут показаться неестественными. Но на самом деле они вполне адекватные. Пусть 
\begin{itemize}
\item $|\alpha_i|\ge |\gamma_i| + |\beta_i|$ для $i=2,\dots, n-1$
\item $\alpha_1 = \alpha_n=1$;
\item $|\beta_1|\le 1$, $|\gamma_n|\le 1$, $|\beta_1| + |\gamma_n|<2$.
\item $\gamma_i,\beta_i\ne0$.
\end{itemize}

Типовой пример такой задачи: $\alpha_i = 2$, $\beta_i = \gamma_i = -1$. Она у нас возникнет, когда мы будем считать численно вот такую краевую задачу
\[
  \begin{cases}
    -u''(x) = f(x);\\
    u(0) = u(1) = 0.
  \end{cases}
\]

Итак, задачу поставили. Давайте её решать. Перепишем систему вот в таком виде
\[
 \begin{cases}\alpha_1 x_1 + \beta_1 x_2 = b,\\
 \dotfill\\
 \gamma_i x_{i-1} + \alpha_i x_i + \beta_i x_{i+1} = b_i;\\
 \dotfill\\
\gamma_n x_{n-1} + \alpha_n x_n = b_n.
\end{cases}
\]
Это будет некая модификация метода Гаусса. Так её обычно описывают. Но я буду несколько проще.

На первом этапе из каких-то соображений нахожу $\{A_i,B_i\}$, для которых $x_i = A_{i+1} x_{i+1}  + B_{i+1}$. Это прямой метод прогонки. $A_i,B_i$ называются прогоночными коэффициентами. На втором этапе обратная прогонка. Берём $x_n$ и находим $x_i$.

Но не всё так просто. Нужно, чтобы $|A_i|\le 1$. Если $A_i\ge A>1$, будет вот что. $x_n$ у нас посчитано будет с какой-то ошибкой. Каждый раз эта ошибка будет умножаться на что-то больше единицы.

Теперь давайте подумаем, как такой набор соотношений получить. Вариантов на самом деле множество.
\[
  x_{i-1} = A_i x_i + B_i
\]
подставим в $i$-е уравнение
\[
  \gamma_i A-i x_i + \gamma_i B_i  + \alpha_i x_i + \beta_i x_{i+1} = b_i.
\]
Мы хотим видеть $x_i = A_{i+1} x_{i+1}  + B_{i+1}$. Значит, надо выразить $x_i$.
\[
  x_i = -\frac{\beta_i}{\gamma_i A_i + \alpha_i} x_{i+1} + \frac{b_i - \gamma_i B_i}{\gamma_i A_i + \alpha_i}.
\]
Мы пока не задумываемся, почему на эти знаменатели можно делить.
\[
  A_{i+1} = \frac{-\beta_i}{\gamma_i A_i + \alpha_i}\quad
  B_{i+1} = \frac{b_i - \gamma_i B_i}{\gamma_i A_i + \alpha_i}.
\]
При этом $A_2 = -\frac{\beta_1}{\alpha_1}$, $B_2 = \frac{b_1}{\alpha_1}$. Осталось определить $x_n$.
\[
  x_n = -\frac{B_n - \frac{b_n}{\gamma_n}}{A_n + \frac{\alpha_n}{\gamma_n}}.
\]

Нам осталось показать, что знаменатели у нас не нули и что $|A_i|\le 1$. Начнём мы парадоксальным образом. Мы знаем, что $\alpha_1 = \alpha_2 = 1$; значит, $A_2 = -\beta_1$, но $|\beta_1|\le 1$ Значит, $|A_2|\le 1$. База индукции есть.

Пусть $|A_i|\le 1$. Покажем, что и $|A_{i+1}|\le 1$. Так как $\beta_i\ne 0$, нужно доказать, что знаменатель не меньше числителя, что и докажет его отличие от нуля
\[
  |\gamma_i A_i + \alpha_i| - |\beta_i|\ge |\alpha_i| - |\gamma_i||A_i| - |\beta_i|\ge |\beta_i| + |\gamma_i| - |\gamma_i||A_i| - |\beta_i| = |\gamma_i|\big(1-|A_i|\big)\ge 0.
\]
Таким образом, мы получили, что $|\gamma_i A_i + \alpha_i|\ge |\beta_i|>0$. То есть мы и поделили хорошо и получили устойчивость алгоритма в целом. Осталось про знаменатель $x_n$ поговорить.
\[
  x_n = \frac{B_n - \frac{b_n}{\gamma_n}}{A_n+\frac1{\gamma_n}} = 
   \frac{\dots}{\gamma_n A_n +1}.
\]
У нас две возможности.
\begin{itemize}
  \item $|\beta_i|<1$. В этом случае $|A_1|<1$, отсюда все $|A_i|<1$ и последняя $|A_n|<1$. Отсюда $A_n\gamma_n + 1\ne 0$.
  \item $|\gamma_n|\le 1$. Тут ещё приятнее. $|A_n|\le 1$ и $|\gamma_n|<1$. Опять всё хорошо.
\end{itemize}

А теперь наш второй этап завишем:
\[
  x_i = A_{i+1} x_{i+1} + B_{i+1}.
\]
Посчитаем сложность алгоритма на двух этапах в целом. $8n + O(1)$ "--- число действий пропорциональна числу неизвестных. Это фактически идеальная ситуация. Это фактически как из массива в массив переложить.
\subsection{Многочлен наилучшего равномерного приближения}
Задача ставится следующим образом. Есть отрезок $[a,b]$, $x\in[a,b)$. Есть функция $f(x)$. Норма в нашим пространстве $\|g\|_C = \sup\limits_{[a,b]}\big|g(x)\big|$. Будем пытаться приблизить функцию многочленами
\[
  f(x)\sim Q_n(x).
\]
Наша цель, чтобы при фиксированным $n$ мы построили такой многочлен степени не выше $n$, для которого
\[
  \Delta_n(f) = \|f- Q_n^0\|_C\le \min\limits_{Q_n}\|f-Q_n\|_C.
\]
Так как пространство у нас линейное нормированное, такой многочлен будет существовать. Вот будет ли он единственный.

Сразу расстрою: общего адекватного алгоритма нет. Даётся только ради традиций, чтоы у преподавателей старой закалки не было культурного шока, что вы это не знаете.

Я сформулирую сразу утверждение, которое в следующий раз будем доказывать. В следующей лекции вы впечатлитесь масштабностью задачи, которая перед нами стоит.

\begin{The}[Чебышёва]
  Пусть $f\in C[a,b]$. Тогда два утверждения равносильны: 
  \begin{enumerate}
  \item $Q_n(x)$ "--- МНРП степени $n$ для $f$ на $[a,b]$;
  \item Существуют $(n+2)$ точки $\{x_i\}\subset [a,b]$, для которых $x_0<x_1<\dots<x_{n+1}$ и
  \[
    f(x_i) = Q_n(x_i) = \alpha(-1)^i\| f - Q_n\|_C,\quad
    j=0,\dots,n+1,
  \]
  $\alpha = 1$ или $\alpha=-1$ для всех $i$.
  \end{enumerate}
\end{The}